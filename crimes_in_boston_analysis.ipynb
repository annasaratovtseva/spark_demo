{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in ./.local/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение путей до папки с исходными данными (input_folder) и папки с результатом (output_folder), введённых при запуске Spark-приложения через spark-submit\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"input_folder\", help = \"Path to the folder with input files offense_codes.csv, crime.csv\")\n",
    "parser.add_argument(\"output_folder\", help = \"Path to the folder with output file crimes_in_boston_analysis.parquet\")\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.0.3\n"
     ]
    }
   ],
   "source": [
    "# Создание SparkSession\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Crimes in Boston - Analysis\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение данных из справочника кодов преступлений\n",
    "offense_codes_df = spark.read.csv(args.input_folder + \"/offense_codes.csv\", header=True, inferSchema=True)\n",
    "offense_codes_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CODE: integer (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Информация о схеме\n",
    "offense_codes_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение данных о преступлениях\n",
    "crime_df = spark.read.csv(args.input_folder + \"/crime.csv\", header=True, inferSchema=True)\n",
    "crime_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INCIDENT_NUMBER: string (nullable = true)\n",
      " |-- OFFENSE_CODE: integer (nullable = true)\n",
      " |-- OFFENSE_CODE_GROUP: string (nullable = true)\n",
      " |-- OFFENSE_DESCRIPTION: string (nullable = true)\n",
      " |-- DISTRICT: string (nullable = true)\n",
      " |-- REPORTING_AREA: string (nullable = true)\n",
      " |-- SHOOTING: string (nullable = true)\n",
      " |-- OCCURRED_ON_DATE: string (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: string (nullable = true)\n",
      " |-- HOUR: integer (nullable = true)\n",
      " |-- UCR_PART: string (nullable = true)\n",
      " |-- STREET: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Информация о схеме\n",
    "crime_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Временные представления:\n",
      "[Table(name='crime', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='crimes_monthly', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='crimes_total_lat_lng', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='frequent_crime_types', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='offense_codes', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='unique_offense_codes', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Регистрация DataFrame как временных представлений\n",
    "offense_codes_df.createOrReplaceTempView(\"offense_codes\")\n",
    "crime_df.createOrReplaceTempView(\"crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|unique_codes_number|codes_number|\n",
      "+-------------------+------------+\n",
      "|                425|         576|\n",
      "+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверка справочника кодов преступлений на наличие дубликатов\n",
    "result = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(DISTINCT code)    AS unique_codes_number,\n",
    "    COUNT(code)             AS codes_number\n",
    "FROM offense_codes\n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------------------------+-------------------------------------+\n",
      "|code|name                                      |crime_type                           |\n",
      "+----+------------------------------------------+-------------------------------------+\n",
      "|243 |RAPE - ATTEMPT - SEXUAL ASSAULT W/ OBJECT |RAPE                                 |\n",
      "|540 |BURGLARY - COMMERICAL - FORCE             |BURGLARY                             |\n",
      "|623 |LARCENY SHOPLIFTING $50 TO $199           |LARCENY SHOPLIFTING $50 TO $199      |\n",
      "|1721|FAILURE TO REGISTER AS A SEX OFFENDER     |FAILURE TO REGISTER AS A SEX OFFENDER|\n",
      "|1903|GAMBLING - EQUIP VIOLATIONS               |GAMBLING                             |\n",
      "|3704|M/V ACCIDENT - POLICE VEHICLE             |M/V ACCIDENT                         |\n",
      "|251 |RAPE - COMPLETE - FORCIBLE                |RAPE                                 |\n",
      "|2622|KIDNAPPING/CUSTODIAL KIDNAPPING           |KIDNAPPING/CUSTODIAL KIDNAPPING      |\n",
      "|804 |STALKING                                  |STALKING                             |\n",
      "|2914|VAL - OPERATING W/O AUTHORIZATION LAWFUL  |VAL                                  |\n",
      "|322 |ROBBERY - OTHER WEAPON - RESIDENCE        |ROBBERY                              |\n",
      "|321 |ROBBERY - OTHER WEAPON - MISCELLANEOUS    |ROBBERY                              |\n",
      "|362 |ROBBERY ATTEMPT - OTHER WEAPON - RESIDENCE|ROBBERY ATTEMPT                      |\n",
      "|613 |LARCENY SHOPLIFTING                       |LARCENY SHOPLIFTING                  |\n",
      "|633 |LARCENY SHOPLIFTING UNDER $50             |LARCENY SHOPLIFTING UNDER $50        |\n",
      "|375 |ROBERRY ATTEMPT - UNARMED - CHAIN STORE   |ROBERRY ATTEMPT                      |\n",
      "|1863|DRUGS - POSS CLASS D - MARIJUANA, ETC.    |DRUGS                                |\n",
      "|2606|PRISONER ATTEMPT TO RESCUE                |PRISONER ATTEMPT TO RESCUE           |\n",
      "|211 |RAPE - FEMALE - FORCE                     |RAPE                                 |\n",
      "|530 |B&E NON-RESIDENCE NIGHT - FORCE           |B&E NON-RESIDENCE NIGHT              |\n",
      "+----+------------------------------------------+-------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Очистка справочника кодов преступлений от дубликатов + расчёт поля crime_type\n",
    "unique_offense_codes_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    code            AS code,\n",
    "    FIRST(name)     AS name,\n",
    "    CASE\n",
    "        WHEN INSTR(FIRST(name), ' -') = 0\n",
    "            THEN FIRST(name)\n",
    "        ELSE\n",
    "            SUBSTR(FIRST(name), 1, INSTR(FIRST(name), ' -') - 1)\n",
    "    END             AS crime_type\n",
    "FROM offense_codes\n",
    "GROUP BY\n",
    "    code\n",
    "\"\"\")\n",
    "\n",
    "unique_offense_codes_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Регистрация DataFrame как временного представления\n",
    "unique_offense_codes_df.createOrReplaceTempView(\"unique_offense_codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверка, что у всех преступлений указан код из справочника кодов преступлений\n",
    "result = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(*)\n",
    "FROM crime                      C\n",
    "LEFT JOIN unique_offense_codes  UOC     ON UOC.code = C.offense_code\n",
    "WHERE UOC.code IS NULL\n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчёт метрик crimes_total, lat, lng\n",
    "crimes_total_lat_lng_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    district                            AS district,\n",
    "    COUNT(DISTINCT incident_number)     AS crimes_total,\n",
    "    AVG(lat)                            AS lat,\n",
    "    AVG(long)                           AS lng\n",
    "FROM crime\n",
    "GROUP BY\n",
    "    district\n",
    "\"\"\")\n",
    "\n",
    "crimes_total_lat_lng_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчёт метрики crimes_monthly\n",
    "crimes_monthly_df = spark.sql(\"\"\"\n",
    "WITH cte AS\n",
    "(\n",
    "    SELECT\n",
    "        district                            AS district,\n",
    "        year                                AS year,\n",
    "        month                               AS month,\n",
    "        COUNT(DISTINCT incident_number)     AS incidents_monthly_count_by_district\n",
    "    FROM crime\n",
    "    GROUP BY\n",
    "        district,\n",
    "        year,\n",
    "        month\n",
    ")\n",
    "SELECT\n",
    "    district                                                        AS district,\n",
    "    PERCENTILE_APPROX(incidents_monthly_count_by_district, 0.5)     AS crimes_monthly\n",
    "FROM cte\n",
    "GROUP BY\n",
    "    district\n",
    "\"\"\")\n",
    "\n",
    "crimes_monthly_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчёт метрики frequent_crime_types\n",
    "frequent_crime_types_df = spark.sql(\"\"\"\n",
    "WITH cte AS\n",
    "(\n",
    "    SELECT\n",
    "        district                                                                                    AS district,\n",
    "        offense_code                                                                                AS offense_code,\n",
    "        COUNT(DISTINCT incident_number)                                                             AS incidents_count_by_district_and_offense_code,\n",
    "        ROW_NUMBER() OVER (PARTITION BY district ORDER BY COUNT(DISTINCT incident_number) DESC)     AS row_number\n",
    "    FROM crime\n",
    "    GROUP BY\n",
    "        district,\n",
    "        offense_code\n",
    "    ORDER BY\n",
    "        district,\n",
    "        row_number\n",
    ")\n",
    "SELECT\n",
    "    T.district                                      AS district,\n",
    "    CONCAT_WS(', ', COLLECT_LIST(UOC.crime_type))   AS frequent_crime_types\n",
    "FROM cte                            T\n",
    "INNER JOIN unique_offense_codes     UOC     ON UOC.code = T.offense_code\n",
    "WHERE T.row_number <= 3\n",
    "GROUP BY\n",
    "    T.district\n",
    "\"\"\")\n",
    "\n",
    "frequent_crime_types_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Регистрация DataFrame как временных представлений\n",
    "crimes_total_lat_lng_df.createOrReplaceTempView(\"crimes_total_lat_lng\")\n",
    "crimes_monthly_df.createOrReplaceTempView(\"crimes_monthly\")\n",
    "frequent_crime_types_df.createOrReplaceTempView(\"frequent_crime_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сборка витрины\n",
    "data_mart_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    T1.district,\n",
    "    T1.crimes_total,\n",
    "    T2.crimes_monthly,\n",
    "    T3.frequent_crime_types,\n",
    "    T1.lat,\n",
    "    T1.lng\n",
    "FROM crimes_total_lat_lng           T1\n",
    "INNER JOIN crimes_monthly           T2  ON IFNULL(T2.district, '') = IFNULL(T1.district, '')\n",
    "INNER JOIN frequent_crime_types     T3  ON IFNULL(T3.district, '') = IFNULL(T1.district, '')\n",
    "ORDER BY\n",
    "    T1.district\n",
    "\"\"\")\n",
    "\n",
    "data_mart_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение витрины в файл crimes_in_boston_analysis.parquet\n",
    "data_mart_df.write.mode(\"overwrite\").parquet(args.output_folder + \"/crimes_in_boston_analysis.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановка SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
